{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08bf9d40",
   "metadata": {},
   "source": [
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣀⣀⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣴⣾⣿⣿⣿⣿⣿⣿⣿⣿⣶⣶⣶⣤⣄⡠⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣴⣾⣿⣿⣿⣿⣿⣼⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣰⣿⣻⣿⣿⣿⣿⣿⣿⣿⠉⠉⠛⠛⠛⠛⠿⣿⣿⣿⣿⣿⣿⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢰⣿⣿⣿⣿⣿⣿⣿⡿⠇⠀⠀⠀⠀⠀⠀⠀⠀⠲⠶⢤⡄⠀⠘⢿⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣿⣿⣿⡿⠁⣂⡀⠀⠀⠀⠀⠀⠦⠤⣽⠷⣾⢷⢮⣀⠀⢻⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⣿⣿⣿⣿⣿⣿⣿⡷⠟⠉⠀⠀⢀⣠⣶⣶⣶⣤⣠⣤⡟⠈⢻⡿⠀⠘⣧⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⣿⣿⣿⡟⠀⠀⠀⠠⠼⠿⢻⣿⣻⣿⣿⣿⣿⣿⣷⣾⣣⣇⡀⢻⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⣿⢿⡿⣿⣿⣿⠁⠀⠀⠀⠲⣶⣷⣿⣿⣿⣿⣿⣿⣿⠟⢻⣟⣿⣿⣿⣾⣷⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣾⠃⡼⣁⢀⣿⠁⠀⠀⠀⠀⠀⠉⠙⢿⣿⣿⣿⣿⣿⣿⠀⢸⣿⣿⣿⣿⣭⣛⠇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⡟⠻⡟⣿⣷⡆⠀⠀⠀⠀⠀⢀⣠⣬⣿⣿⣿⣿⡋⠀⠈⢻⣟⣿⣌⣻⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣿⢷⣤⢁⣿⡿⣿⣀⣀⢀⡀⣼⠿⠟⢋⣿⣿⣿⣯⢉⣓⣂⠈⣿⠙⣿⠉⢿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠡⣤⡷⣾⣿⠷⢻⣿⣷⣿⣿⡟⢀⣴⣿⣿⣿⣿⣿⣿⣿⣿⡟⣿⣼⣷⠀⣼⡆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⢀⣿⠛⣷⣴⣻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⠗⢿⣽⡏⣸⠟⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡇⢸⣿⣟⠙⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡻⢶⣿⣏⣙⡋⢳⣦⣿⣵⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠁⢸⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣶⣭⣽⣿⣿⡊⢹⣿⡿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠉⣿⣿⡇⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠙⠿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣷⣾⣿⡃⣤⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⠀⠀⠀⠀⠀⠀⠀⠈⠹⠻⣿⣿⣿⣿⢟⣿⣿⣿⣿⣿⣿⣿⣿⡿⠇⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⡟⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠹⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣿⣯⡿⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣀⣀⣠⣤⠶⠿⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠒⣿⣿⣿⣿⣿⣿⣿⣿⣿⡿⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⢀⣀⣤⡶⠖⠛⠛⠉⠉⣁⣤⠄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⠀⣿⣿⡿⠉⠁⢸⠉⠉⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⢀⣤⣶⠿⠛⠉⠀⠀⠀⠀⠀⠀⣼⡏⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⡀⠀⠀⢰⣾⣿⡷⠀⠀⣾⡄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠟⠁⠀⠀⠃⢀⠈⠉⢁⣨⣭⣿⡿⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢺⡇⠀⣀⣿⣿⡏⠀⠀⠀⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⡀⠀⠠⠆⠒⣿⣶⣾⣿⣿⣿⡿⡂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣷⠀⣿⣿⡏⠀⢸⠁⠀⡙⠷⢦⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⣿⣶⣦⣶⣿⣿⣿⣿⣿⣿⣿⣧⣥⣄⡀⠀⠀⠀⣄⣀⠀⠀⡀⠀⠀⠀⣿⣿⣿⢿⣿⢀⣴⡻⠀⠀⣧⠀⠀⠈⠛⠶⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⣿⣿⣷⣄⠀⠀⠀⠈⠉⠉⠉⠉⠛⠛⠛⠛⠿⠿⠿⣿⣷⣶⣿⣄⠀⢰⣿⢻⣿⣸⣿⣾⠁⠁⠇⠀⢿⣷⡤⣄⣀⠀⠈⠻⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠈⠻⠿⣿⣧⠀⠀⠀⠀⠀⠀⠀⡀⠀⠀⠀⠀⠀⣀⠀⠈⠉⠙⠿⠷⣿⣏⠀⣿⣿⣿⡇⠀⠈⡀⠀⠈⠻⣷⡈⠻⢿⣤⠀⠈⠻⣦⣀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠉⠋⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⡋⠀⠉⠠⠀⠈⠻⣄⢹⣿⡟⢀⣀⡴⢿⣶⠒⠺⠟⠛⠂⠀⢻⡆⢰⣶⣬⣍⣉⠓⠶⣤⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣷⠀⠀⠂⠶⢤⣄⡙⠀⠻⠁⣾⣿⣦⣀⠀⠀⠀⠀⠀⠀⠀⠀⠻⣾⣿⣿⡟⠋⠙⠓⠂⠙⠓⠒⠶⢤⣤⡀⠀⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠰⠿⠶⠀⠈⠀⠒⠀⢺⣿⣷⣿⣙⡻⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⢿⣷⣀⢤⡴⢄⠀⠀⠀⠀⠀⠀⠉⠳⠦⣄⠀⠀⠀\n",
    "⠈⠁⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢈⠀⠀⠘⣿⣿⡿⣿⡟⠃⠀⠀⠀⠀⠀⠀⠀⠐⠄⠠⠀⡈⡻⣯⣷⣘⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻⣦⡀\n",
    "⠴⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠘⠳⣄⠀⢸⣿⣿⡄⠀⠀⠀⠀⠀⠀⠀⠐⠒⠂⠊⠈⠈⠁⠀⠀⠙⢿⣿⣦⡀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠻\n",
    "⠀⠀⠐⠂⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠠⠄⠀⠀⠙⠀⢸⣿⣿⣿⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠉⣹⣿⠷⣦⣁⠂⠀⠀⠀⠀⠀⠀\n",
    "⠤⠄⠀⠀⠀⣀⡀⢀⡀⠤⠀⠉⢀⣀⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⣿⣆⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⣿⣦⠈⠛⢷⣄⠀⠀⠀⠀⠀\n",
    "⠛⠀⠀⠀⠀⠀⠠⠄⢀⡀⢀⣤⢠⣄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣿⠿⣿⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢿⣿⣦⠀⠈⠙⠀⠀⠀⠀⠀\n",
    "⠀⠀⠀⣐⣂⣀⣀⠀⣶⣶⣾⢉⣴⢾⣿⣷⣤⣤⣤⣤⣠⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣿⣿⣿⡄⢀⣀⠀⠄⠈⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⠀⠀⠀⠀⢸⣿⣿⣦⡀⣀⣀⣀⣀⠀⢀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d55bcf",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46ea275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d54c4f5",
   "metadata": {},
   "source": [
    "### Sctipt constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71c69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 30\n",
    "WINDOW_SIZE = 50\n",
    "TRAIN_STEPS_PER_EPOCH = 80\n",
    "EVAL_STEPS_PER_EPOCH = 20\n",
    "K_FOLDS = 8\n",
    "REPETITION_DURATION = 30\n",
    "LOG_PER_STEPS = 20\n",
    "DATA_CSV_PATH = 'data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1f05ce",
   "metadata": {},
   "source": [
    "### Prepate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0be96b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_CSV_PATH, sep=';')\n",
    "\n",
    "x_data = df[['PITCH', 'ROLL', 'YAW']].values\n",
    "y_data = df['FLAG'].values\n",
    "\n",
    "# Replace single ones with sequences (of REPETITION_DURATION length) ex.\n",
    "# [0,0,1,0,0,0,0,1,0,0,0,0] -> [0,0,1,1,1,0,0,1,1,1,0,0] (REPETITION_DURATION=3)\n",
    "repetition_duration_time = 0\n",
    "for i in range(len(y_data)):\n",
    "    if y_data[i] == 1:\n",
    "        repetition_duration_time = REPETITION_DURATION\n",
    "    y_data[i] = min(1, repetition_duration_time)\n",
    "    repetition_duration_time = max(0, repetition_duration_time - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae10d6eb",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101fc4b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 36, 1, 64)         2944      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 36, 1, 64)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 22, 1, 64)         61504     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 22, 1, 64)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 1, 64)          61504     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 8, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 250)               128250    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 254,453\n",
      "Trainable params: 254,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (15, 3), strides=(1, 1), activation='relu', input_shape=(WINDOW_SIZE, 3, 1)),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(64, (15, 1), strides=(1, 1), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Conv2D(64, (15, 1), strides=(1, 1), activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(250, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6357f3d",
   "metadata": {},
   "source": [
    "### Set up binary classification components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481018c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "train_acc_metric = tf.keras.metrics.BinaryAccuracy()\n",
    "eval_acc_metric = tf.keras.metrics.BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d28d6c0",
   "metadata": {},
   "source": [
    "### Generator function that sample window from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ba07f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(possible_window_indexes, x_data, y_data):\n",
    "    while True:\n",
    "        window_start = random.choice(possible_window_indexes)\n",
    "        window = x_data[window_start : window_start + WINDOW_SIZE]\n",
    "        yield window, [y_data[window_start]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ebc836",
   "metadata": {},
   "source": [
    "### Train and evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fbd1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Fold 1/8\n",
      "Training loss at step 0: 2.1910\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 1.0112\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 1.1129\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.9474\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.8358\n",
      "Validation acc: 0.8883\n",
      "Time taken: 2.77s \n",
      "\n",
      "Fold 2/8\n",
      "Training loss at step 0: 0.3439\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.4445\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.3308\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.8544\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.8471\n",
      "Validation acc: 0.8517\n",
      "Time taken: 2.69s \n",
      "\n",
      "Fold 3/8\n",
      "Training loss at step 0: 0.3266\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.0928\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.6597\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.3650\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.8650\n",
      "Validation acc: 0.9167\n",
      "Time taken: 2.30s \n",
      "\n",
      "Fold 4/8\n",
      "Training loss at step 0: 0.3745\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.3017\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.6568\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.3927\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.8854\n",
      "Validation acc: 0.8983\n",
      "Time taken: 2.40s \n",
      "\n",
      "Fold 5/8\n",
      "Training loss at step 0: 0.2633\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.3686\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.5280\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.3716\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.8842\n",
      "Validation acc: 0.8900\n",
      "Time taken: 2.37s \n",
      "\n",
      "Fold 6/8\n",
      "Training loss at step 0: 0.2799\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.1967\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.1797\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.3472\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.9038\n",
      "Validation acc: 0.9550\n",
      "Time taken: 2.40s \n",
      "\n",
      "Fold 7/8\n",
      "Training loss at step 0: 0.4268\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.2758\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.0983\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.2645\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.8975\n",
      "Validation acc: 0.9533\n",
      "Time taken: 2.74s \n",
      "\n",
      "Fold 8/8\n",
      "Training loss at step 0: 0.4771\n",
      "Seen so far: 30 samples\n",
      "Training loss at step 20: 0.3423\n",
      "Seen so far: 630 samples\n",
      "Training loss at step 40: 0.2728\n",
      "Seen so far: 1230 samples\n",
      "Training loss at step 60: 0.1609\n",
      "Seen so far: 1830 samples\n",
      "Training acc over epoch: 0.9013\n",
      "Validation acc: 0.8733\n",
      "Time taken: 2.64s \n",
      "\n",
      "Epoch 2/100\n",
      "Fold 1/8\n",
      "Training loss at step 0: 0.2503\n",
      "Seen so far: 30 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_fn(y_batch_train, out)\n\u001b[0;32m     49\u001b[0m grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss_value, model\u001b[38;5;241m.\u001b[39mtrainable_weights)\n\u001b[1;32m---> 50\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m train_acc_metric\u001b[38;5;241m.\u001b[39mupdate_state(y_batch_train, out)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m LOG_PER_STEPS \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:672\u001b[0m, in \u001b[0;36mOptimizerV2.apply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    669\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_gradients(grads_and_vars)\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optimizer_utils\u001b[38;5;241m.\u001b[39mstrategy_supports_no_merge_call():\n\u001b[1;32m--> 672\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mapply_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[0;32m    676\u001b[0m       functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distributed_apply, apply_state\u001b[38;5;241m=\u001b[39mapply_state),\n\u001b[0;32m    677\u001b[0m       args\u001b[38;5;241m=\u001b[39m(grads_and_vars,),\n\u001b[0;32m    678\u001b[0m       kwargs\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m    679\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[0;32m    680\u001b[0m       })\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:721\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply\u001b[1;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(var):\n\u001b[0;32m    718\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m name_scope_only_in_function_or_graph(\n\u001b[0;32m    719\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eagerly_outside_functions \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    720\u001b[0m       var\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39mname):\n\u001b[1;32m--> 721\u001b[0m     update_op \u001b[38;5;241m=\u001b[39m \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39min_cross_replica_context():\n\u001b[0;32m    724\u001b[0m       \u001b[38;5;66;03m# In cross-replica context, extended.update returns a list of\u001b[39;00m\n\u001b[0;32m    725\u001b[0m       \u001b[38;5;66;03m# update ops from all replicas (group=False).\u001b[39;00m\n\u001b[0;32m    726\u001b[0m       update_ops\u001b[38;5;241m.\u001b[39mextend(update_op)\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2634\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2631\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[0;32m   2632\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2633\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[1;32m-> 2634\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2636\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[0;32m   2637\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3709\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   3706\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[0;32m   3707\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[0;32m   3708\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[1;32m-> 3709\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3715\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   3711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[0;32m   3712\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[0;32m   3713\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[0;32m   3714\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[1;32m-> 3715\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3716\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[0;32m   3717\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:601\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    600\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:704\u001b[0m, in \u001b[0;36mOptimizerV2._distributed_apply.<locals>.apply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_apply_args:\n\u001b[0;32m    703\u001b[0m   apply_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply_state\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m apply_state\n\u001b[1;32m--> 704\u001b[0m update_op \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resource_apply_dense(grad, var, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mapply_kwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m var\u001b[38;5;241m.\u001b[39mconstraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcontrol_dependencies([update_op]):\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:142\u001b[0m, in \u001b[0;36mSGD._resource_apply_dense\u001b[1;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[0;32m    133\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mraw_ops\u001b[38;5;241m.\u001b[39mResourceApplyKerasMomentum(\n\u001b[0;32m    134\u001b[0m       var\u001b[38;5;241m=\u001b[39mvar\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    135\u001b[0m       accum\u001b[38;5;241m=\u001b[39mmomentum_var\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m       use_locking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_locking,\n\u001b[0;32m    140\u001b[0m       use_nesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnesterov)\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResourceApplyGradientDescent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m      \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoefficients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr_t\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdelta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_locking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_locking\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py:404\u001b[0m, in \u001b[0;36mkwarg_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args:\n\u001b[0;32m    400\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{f}\u001b[39;00m\u001b[38;5;124m only takes keyword args (possible keys: \u001b[39m\u001b[38;5;132;01m{kwargs}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    402\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease pass these args as kwargs instead.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    403\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(f\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, kwargs\u001b[38;5;241m=\u001b[39mf_argspec\u001b[38;5;241m.\u001b[39margs))\n\u001b[1;32m--> 404\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Desktop\\pliki\\pwr\\3\\szyc\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_training_ops.py:1934\u001b[0m, in \u001b[0;36mresource_apply_gradient_descent\u001b[1;34m(var, alpha, delta, use_locking, name)\u001b[0m\n\u001b[0;32m   1932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   1933\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1934\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1935\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mResourceApplyGradientDescent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1936\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muse_locking\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_locking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1938\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for fold in range(K_FOLDS):\n",
    "        print(f\"Fold {fold+1}/{K_FOLDS}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Reduce possible window starts to make sure that:\n",
    "        fold_size = int(len(x_data)/K_FOLDS)\n",
    "        fold_start = fold * fold_size\n",
    "        fold_end = (fold + 1) * fold_size\n",
    "        # 1. Windowed training data in range [0, fold_start) does not overlap eval data\n",
    "        range1 = range(0         , fold_start  - WINDOW_SIZE - 1)\n",
    "        # 2. Windowed eval data in range [fold_start, fold_end) does not overlap train data\n",
    "        range2 = range(fold_start, fold_end    - WINDOW_SIZE - 1)\n",
    "        # 3. Windowed training data in range [fold_end, len(x_data)) does not overlap eval data\n",
    "        range3 = range(fold_end  , len(x_data) - WINDOW_SIZE - 1)\n",
    "        \n",
    "        possible_window_starts = list(range1) + list(range2) + list(range3)\n",
    "        \n",
    "        # This range will be used for eval (to know why read aboud k-fold algorithm)\n",
    "        # Last fold is sometimes longer because ex.\n",
    "        # data_length=9 and K_FOLDS=2, so you cant split 9 samples into 2 folds so last fold is 5 length (first is 4)\n",
    "        fold_range = range(fold_start, fold_end) if (fold < K_FOLDS - 1) else range(fold_start, len(x_data))\n",
    "        \n",
    "        # Prepare train dataset\n",
    "        possible_train_indexes = [i for i in possible_window_starts if i not in fold_range]\n",
    "        train_dataset = tf.data.Dataset.from_generator(\n",
    "            data_generator,\n",
    "            args=(possible_train_indexes, x_data, y_data),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(WINDOW_SIZE, 3), dtype=tf.uint8),\n",
    "                tf.TensorSpec(shape=(1), dtype=tf.uint8)\n",
    "            )\n",
    "        )\n",
    "        train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "        \n",
    "        # Train\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset.take(TRAIN_STEPS_PER_EPOCH)):\n",
    "            with tf.GradientTape() as tape:\n",
    "                out = model(x_batch_train, training=True)\n",
    "                loss_value = loss_fn(y_batch_train, out)\n",
    "            grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "            \n",
    "            train_acc_metric.update_state(y_batch_train, out)\n",
    "            \n",
    "            if step % LOG_PER_STEPS == 0:\n",
    "                print(\"Training loss at step %d: %.4f\" % (step, float(loss_value)))\n",
    "                print(\"Seen so far: %d samples\" % ((step + 1) * BATCH_SIZE))\n",
    "         \n",
    "        train_acc = train_acc_metric.result()\n",
    "        train_acc_metric.reset_states()\n",
    "        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "        # Prepare eval dataset\n",
    "        possible_eval_indexes  = [i for i in possible_window_starts if i in fold_range]\n",
    "        eval_dataset = tf.data.Dataset.from_generator(\n",
    "            data_generator,\n",
    "            args=(possible_eval_indexes, x_data, y_data),\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(WINDOW_SIZE, 3), dtype=tf.uint8),\n",
    "                tf.TensorSpec(shape=(1), dtype=tf.uint8)\n",
    "            )\n",
    "        )\n",
    "        eval_dataset = eval_dataset.batch(BATCH_SIZE)\n",
    "        \n",
    "        # Eval dataset\n",
    "        for x_batch_eval, y_batch_eval in eval_dataset.take(EVAL_STEPS_PER_EPOCH):\n",
    "            eval_out = model(x_batch_eval, training=False)\n",
    "            eval_acc_metric.update_state(y_batch_eval, eval_out)\n",
    "        \n",
    "        eval_acc = eval_acc_metric.result()\n",
    "        eval_acc_metric.reset_states()\n",
    "        print(\"Validation acc: %.4f\" % (float(eval_acc),))\n",
    "        \n",
    "        print(\"Time taken: %.2fs \\n\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d5a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
